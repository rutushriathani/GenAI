{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ANKdpu9wwIPa",
    "outputId": "d3841dbd-3424-4f31-a524-a6987d7a3ffe"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.6)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch accelerate sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "print(\"Setup Complete!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FPrbCe2S8SJ7",
    "outputId": "85e82842-9ae5-49ba-97f8-db826aab1401"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Setup Complete!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a summarization pipeline using a powerful model\n",
    "app_model = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Test it with a sample sentence\n",
    "text = \"Generative AI is a field that focuses on creating models capable of generating human-like content.\"\n",
    "print(app_model(text))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382,
     "referenced_widgets": [
      "a9e569ec826b4aa2b021d98261d4ce92",
      "84e15b6bbc4a4c27b531f5293e201b0d",
      "d0339ad640f94df3bffe54e938c6462c",
      "f3ecb23bb9834959b21bdcc9a37fd883",
      "dc07001a52db4e8ba1bfb617869c4535",
      "acf14e131d4a47bca15360c22072d154",
      "e10bf9bb646449fcb0749a2282323af5",
      "0000df1a30fd403095cb1b97d238c719",
      "d16c688cfd8a4db4aae3aeccb33a4ec5",
      "97cf319f21944aa893d7498330594121",
      "bc56cd294bf844b9a1000cf2f49a9b95",
      "f36163d5c9d14045b655c9d35e473832",
      "4ec9c2c6db9148d5a24787efac928871",
      "76c1021ec578439c937d5f1ff5913de1",
      "99d54405e1f548a3afbfccc5da851e7b",
      "d27f7d3eca364805bb4daa01f77a4856",
      "4156ab61bb24445783251f7e4d37a314",
      "9a19f751b6b2499498f96b008b5745de",
      "39d7258172954cdfafc71ffc23e65ebf",
      "7fcacb4f0ea340e98e809cee3ea59b3b",
      "68dd7cf5eef0437bae742810eb13fa3f",
      "b49eec1ef4f2423e8903dd809435c85a",
      "3fb3c111eacc45ce8ff1b9ccffd5e5de",
      "0953533531a14bff95b6e5f7ab9fe16b",
      "a3f97a444da848ba973ff28da3060416",
      "e6948c5a64a5490686ee8ead4f978c17",
      "bcda4a0680a0438abefcda26132862db",
      "896fe0681c3246e48a6e94f9a62068b4",
      "431c0493190d4ee484daeee3ef2ff487",
      "e42ad965cd8c4c1481e1442e9c00b79a",
      "4dbed11405844fe1af8d719d885f5584",
      "54a7aee4a5ab4669bc1a14dfe9529e05",
      "a7811cc6c2b842f9ba1a852ed72abb22",
      "7b4775f475d74025a289f05dd31ceb94",
      "49f63e5573094e80b8e0020087975d23",
      "fecbe8d804a945cdb5bd0b634ec0bd11",
      "ce410c5720814ebc808b127d648276ac",
      "b2814d2cbdae4633a046eb5aa57a3c2a",
      "3396ac064fec42ac8c3d2f9c82587386",
      "091246bbc8fd40e99cdfb07af9ddee02",
      "49d20b7fe3ab49409d899310db536c03",
      "a145722c0797401ca6341584ffe9c146",
      "29cc704f06a4490b82aa9e81a1b85cd6",
      "4ba15dbaad6e4bd684e322681ed4d88a",
      "36ed742739504a919ef4ab66d4c00137",
      "8a76b4ee2f804684a055c3e78a26454b",
      "b6c15e80fa3d475db15f272582475af1",
      "1fa6d1370062478da88359d2d62ccd7e",
      "5755dca943e74b67a676fa7683a5e4d6",
      "42ed97940c0844048d98aeb6fe7e9870",
      "97f7e3b6d06a47b794471167377eeec4",
      "ddde9dc55cf541bc944144421e620bbe",
      "afdd5029374a4cde8c6c39e3d2226193",
      "1623a9fb9d14426d8818f3f6c4c50d3a",
      "be40c70e18f942a7b603361e0bf4a695",
      "85c1181221a44c5ebe0b8e70cc201f20",
      "f74baa9f284b46d0bb3d8321d80b88ae",
      "40f2030fb9c040e9b5a28662df93636a",
      "63f33194a3c24a6a88ba7c8160f4383c",
      "641c007a81a74ece8c6c54b35a52e27c",
      "c28a0c7e29de47b29d09895f48c80230",
      "6c195698683147a88a84bf32fe5c6155",
      "83fa6618e30748f78671aba6da09569d",
      "1299550cba7c4f1f910739b1e57b2841",
      "5bcb82156c6249d8a82f01ba46e5026d",
      "17801a54a8db4fd8a4eb4f23efb56371"
     ]
    },
    "id": "hD_pYHgi8fvl",
    "outputId": "66670c98-b020-4255-d09b-8f41937901e4"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9e569ec826b4aa2b021d98261d4ce92"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f36163d5c9d14045b655c9d35e473832"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3fb3c111eacc45ce8ff1b9ccffd5e5de"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b4775f475d74025a289f05dd31ceb94"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36ed742739504a919ef4ab66d4c00137"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85c1181221a44c5ebe0b8e70cc201f20"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cpu\n",
      "Your max_length is set to 142, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'summary_text': 'Generative AI is a field that focuses on creating models capable of generating human-like content. Generative AI can be used to create content that looks like a human face or a human body. It can also be used as a tool to predict what people will want to see or hear.'}]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Loading the 'Smart' model for high-quality summarization\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZNKEoQV8rYF",
    "outputId": "9b1fa23b-3a56-4da6-877f-38515041a99c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "news_article = \"\"\"\n",
    "PASTE YOUR LONG TEXT HERE:\n",
    "For example, a long paragraph about your recent research on\n",
    "AI+ML+Cyber or domain-aware load balancing.\n",
    "\"\"\""
   ],
   "metadata": {
    "id": "ZxBlBWSV9AG5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Generate the summary\n",
    "summary = summarizer(news_article, max_length=130, min_length=30, do_sample=False)\n",
    "\n",
    "print(\"--- ORIGINAL TEXT ---\")\n",
    "print(news_article)\n",
    "print(\"\\n--- TL;DR SUMMARY ---\")\n",
    "print(summary[0]['summary_text'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BFlbXvqh9CoT",
    "outputId": "6582f0e4-bf30-4ef3-db06-6e8eeece1132"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Your max_length is set to 130, but your input_length is only 42. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=21)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- ORIGINAL TEXT ---\n",
      " \n",
      "PASTE YOUR LONG TEXT HERE: \n",
      "For example, a long paragraph about your recent research on \n",
      "AI+ML+Cyber or domain-aware load balancing.\n",
      "\n",
      "\n",
      "--- TL;DR SUMMARY ---\n",
      "For example, a long paragraph about your recent research on AI+ML+Cyber or domain-aware load balancing.  PASTE YOUR LONG TEXT HERE.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# This creates the analyzer prototype\n",
    "analyzer = pipeline(\"sentiment-analysis\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216,
     "referenced_widgets": [
      "ca2637a5d1f7404081d6d45f989367c0",
      "c065dbdecfef4b83a55ea5a497374173",
      "ad3663cc250a4010967dfb1d6678aeba",
      "5a4a5b84f2a4498daac633e6357060e7",
      "aafe494485404830bec3b681477e664e",
      "367e10f7952847538adc655e2e32d66d",
      "f7a30983e2fe4f79a566c5072f8fd480",
      "d63010bf76324747928e3332d3b7663a",
      "407f55eef82b4797978995df04cb46a6",
      "6b887aceb0684833ac738daf51395bec",
      "91c9cf09384c4f29a813eb9c9720dd1f",
      "94adfd5f6ba44ee7bd002a3705bf2108",
      "a4723b0c0012406ba92448b1dd835fef",
      "66873f8bebe3496fadac0b5bb223f6d2",
      "945e6c9eb41646b5a19e9e7b6b6db8b9",
      "e3436cb0245c421f81e89e1e8d9223e0",
      "340cb56e06364bf18d8ef16d66f668fe",
      "9d3d0d91948243319105fd4a8199071a",
      "9375045b2fdb4d9eb1c95953139867c7",
      "97f75f7ce5a8400087dc97e9a942ef2f",
      "e5a4b4d5fbc74dbda9e68dea16978573",
      "fba297af8a8f4ee0905a96124d15ce20",
      "84ed8b28bbb247259d51f8a256dd9ac1",
      "c6d9076b442a4af68bf45b2ed284fa59",
      "034dace7c0ef44429d4ed0952eed2f42",
      "34779f64e7154f96ac7c41c990086599",
      "6633f9b499c54e06b0aa1f343b126a8f",
      "6c20a561a13a41cf8757ecead7dea2dc",
      "1e8f98799ef344978a3c3d7de96aea93",
      "2160c7763954420aa7a9a65375d408ae",
      "c5337a11e552424aac3e1cc343b778a3",
      "30f98f576c9e4557af2949afdaa82405",
      "068f5338ee334f46a69083570d001892",
      "3097ec29331c4390a4e65765c6c0d912",
      "d17e9473bab444dfa5a66dc29fcb0614",
      "aaecfe38c12c45ba813dab02593b6b51",
      "0677353948ed423aa582782ecb1f1067",
      "bfaa28a8e48a4202bc2c31ee102c7840",
      "92d16eb2cc86408a80ab6b0de1d701b3",
      "4229324eb4f34a71b68d47669899b2a6",
      "e8d6a62a2a414801b3ac3f538ea30799",
      "7c37a4fa514847e49c82ffb40a384f70",
      "ed762de88bb64b28b0dd92a84e3ef55b",
      "b89fe6bc6ba644a3972cd723b82c1716"
     ]
    },
    "id": "sbC-Gtw69IH6",
    "outputId": "5129d3b4-95a9-4a98-dfb2-2971d7ef3256"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca2637a5d1f7404081d6d45f989367c0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "94adfd5f6ba44ee7bd002a3705bf2108"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84ed8b28bbb247259d51f8a256dd9ac1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3097ec29331c4390a4e65765c6c0d912"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# A list of product reviews to analyze\n",
    "reviews = [\n",
    "    \"I absolutely love this product! It has changed my daily routine for the better.\",\n",
    "    \"The build quality is poor and it arrived broken. Very disappointed.\",\n",
    "    \"It works as expected, but the price is a bit high for what you get.\",\n",
    "    \"Incredible customer service. They resolved my issue within minutes!\"\n",
    "]"
   ],
   "metadata": {
    "id": "p7ACfCKX9jJ7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"--- Customer Feedback Analysis Results ---\")\n",
    "\n",
    "for review in reviews:\n",
    "    result = analyzer(review)[0]\n",
    "    sentiment = result['label']\n",
    "    score = result['score']\n",
    "\n",
    "    # Simple formatting to make it readable\n",
    "    print(f\"Review: {review[:50]}...\")\n",
    "    print(f\"Sentiment: {sentiment} ({score:.2%})\\n\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GXg610RM9m4W",
    "outputId": "09a2425f-4f16-4d74-fb7b-75c28ecd1d3e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Customer Feedback Analysis Results ---\n",
      "Review: I absolutely love this product! It has changed my ...\n",
      "Sentiment: POSITIVE (99.98%)\n",
      "\n",
      "Review: The build quality is poor and it arrived broken. V...\n",
      "Sentiment: NEGATIVE (99.98%)\n",
      "\n",
      "Review: It works as expected, but the price is a bit high ...\n",
      "Sentiment: POSITIVE (99.70%)\n",
      "\n",
      "Review: Incredible customer service. They resolved my issu...\n",
      "Sentiment: POSITIVE (99.96%)\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Sorting logic to find negative reviews\n",
    "negative_feedback = [r for r in reviews if analyzer(r)[0]['label'] == 'NEGATIVE']\n",
    "\n",
    "print(f\"Action Required: Found {len(negative_feedback)} unhappy customers.\")\n",
    "for nf in negative_feedback:\n",
    "    print(f\"- {nf}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2FGDznSV9rcu",
    "outputId": "6e6a4d55-0a31-4009-f9d4-bd94f6bfee1a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Action Required: Found 1 unhappy customers.\n",
      "- The build quality is poor and it arrived broken. Very disappointed.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "L8mXqZiq9stN"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}